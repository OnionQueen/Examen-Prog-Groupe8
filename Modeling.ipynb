{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9c4d4b2",
   "metadata": {},
   "source": [
    "# Modeling – Heart Disease Prediction\n",
    "\n",
    "Ce notebook vise à entraîner et comparer plusieurs modèles de classification\n",
    "afin de prédire la présence d’une maladie cardiaque à partir des données cliniques.\n",
    "Les modèles sont évalués à l’aide de métriques adaptées.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed5d0029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1ee42d",
   "metadata": {},
   "source": [
    "## Chargement du pipeline de preprocessing\n",
    "\n",
    "Le pipeline de preprocessing sauvegardé lors de la phase précédente est chargé\n",
    "afin d’assurer la cohérence entre les transformations appliquées aux données\n",
    "d’entraînement et de test.\n",
    "\n",
    "Cette approche permet de séparer clairement les étapes de preprocessing et de\n",
    "modélisation, tout en garantissant la reproductibilité du projet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55a67bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "preprocessor = joblib.load(\"models/preprocessor.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d34f9e",
   "metadata": {},
   "source": [
    "## Chargement des données et séparation train/test\n",
    "\n",
    "Les données sont rechargées et séparées en jeux d’entraînement et de test\n",
    "en utilisant les mêmes paramètres que lors de la phase de preprocessing,\n",
    "afin d’assurer la cohérence des résultats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1d1d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Rechargement du dataset\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "# Suppression de l'identifiant\n",
    "df = df.drop(columns=[\"id\"])\n",
    "\n",
    "# Séparation X / y\n",
    "X = df.drop(columns=[\"num\"])\n",
    "y = df[\"num\"]\n",
    "\n",
    "# Split train / test (mêmes paramètres)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea78439",
   "metadata": {},
   "source": [
    "## Données utilisées\n",
    "\n",
    "Les données ont été préparées dans le notebook de preprocessing.\n",
    "Les jeux d’entraînement et de test ainsi que le pipeline de preprocessing\n",
    "sont utilisés afin d’entraîner les modèles sans fuite de données.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c21c33a",
   "metadata": {},
   "source": [
    "## Modèle 1 – Régression logistique (baseline)\n",
    "\n",
    "La régression logistique est utilisée comme modèle de référence en raison de sa\n",
    "simplicité et de son interprétabilité. Elle permet d’évaluer rapidement si les\n",
    "variables contiennent un signal prédictif pertinent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8964d6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5869565217391305, 0.5614639051891325)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = Pipeline(steps=[\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"model\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = log_reg.predict(X_test)\n",
    "\n",
    "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
    "f1_lr = f1_score(y_test, y_pred_lr, average=\"weighted\")\n",
    "\n",
    "acc_lr, f1_lr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcb08bd",
   "metadata": {},
   "source": [
    "## Modèle 2 – Random Forest\n",
    "\n",
    "Les Random Forest sont des modèles ensemblistes capables de modéliser des relations\n",
    "non linéaires entre les variables. Ils sont généralement robustes et performants\n",
    "sur des données tabulaires.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "903d7e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5869565217391305, 0.5687354137080654)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = Pipeline(steps=[\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"model\", RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average=\"weighted\")\n",
    "\n",
    "acc_rf, f1_rf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce9ec24",
   "metadata": {},
   "source": [
    "## Modèle 3 – Gradient Boosting\n",
    "\n",
    "Le Gradient Boosting combine plusieurs modèles faibles afin d’améliorer\n",
    "progressivement les performances. Il est souvent très performant pour les\n",
    "problèmes de classification structurés.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dcd8b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6141304347826086, 0.59259280658674)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = Pipeline(steps=[\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"model\", GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "\n",
    "acc_gb = accuracy_score(y_test, y_pred_gb)\n",
    "f1_gb = f1_score(y_test, y_pred_gb, average=\"weighted\")\n",
    "\n",
    "acc_gb, f1_gb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49a59442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.561464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.568735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.592593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  F1-score\n",
       "0  Logistic Regression  0.586957  0.561464\n",
       "1        Random Forest  0.586957  0.568735\n",
       "2    Gradient Boosting  0.614130  0.592593"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    \"Model\": [\n",
    "        \"Logistic Regression\",\n",
    "        \"Random Forest\",\n",
    "        \"Gradient Boosting\"\n",
    "    ],\n",
    "    \"Accuracy\": [\n",
    "        acc_lr,\n",
    "        acc_rf,\n",
    "        acc_gb\n",
    "    ],\n",
    "    \"F1-score\": [\n",
    "        f1_lr,\n",
    "        f1_rf,\n",
    "        f1_gb\n",
    "    ]\n",
    "})\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49030f37",
   "metadata": {},
   "source": [
    "## Comparaison des modèles\n",
    "\n",
    "La régression logistique sert de modèle de référence mais présente des performances\n",
    "limitées. Les modèles ensemblistes obtiennent de meilleurs résultats, indiquant\n",
    "la présence de relations non linéaires dans les données.\n",
    "\n",
    "Le modèle de Gradient Boosting sera retenu pour la phase d’optimisation des\n",
    "hyperparamètres.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
